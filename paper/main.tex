\documentclass[11pt]{article}
\usepackage{float}
\usepackage[inline,shortlabels]{enumitem}
\usepackage{amssymb, amsmath, amsthm}
\usepackage{mathrsfs}
\usepackage{tabulary}
\usepackage{rotating}
\usepackage{enumerate}
\usepackage{setspace}
\usepackage{multirow}
\usepackage{paralist}
\usepackage{listings}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\setlength{\parindent}{4em}
\usepackage{dsfont}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{amsmath}

\DeclareMathOperator*{\argmax}{arg\,max}
\renewcommand{\d}{\mathsf{d}}
\newcommand{\E}{\mathsf{E}}

\usepackage{graphicx}
\usepackage{url}
\usepackage{booktabs}

\usepackage{authblk}
\usepackage{etoolbox}
\usepackage{longtable}
\usepackage[numbers,super,sort&compress]{natbib}
\usepackage[usenames,dvipsnames]{color}
\usepackage{natbib}
\bibliographystyle{plainnat}

\usepackage{caption}
\usepackage{hyperref}

\usepackage[hmargin=2.54cm,vmargin=2.54cm]{geometry}
\usepackage[utf8]{inputenc}

\title{Learning Optimal Dynamic Treatment Regimes from Longitudinal Data}

\vspace{3cm}

\author[1]{Nicholas T. Williams, MPH}
\author[1]{Kara E. Rudolph, PhD}
\author[2]{Iv\'an D\'iaz, PhD}
\affil[1]{\footnotesize Department of Epidemiology, Mailman School of Public Health, Columbia University, New York, New York}
\affil[2]{\footnotesize Division of Biostatistics, Department of Population
  Health Sciences, Weill Cornell Medicine, New York, New York}
\date{}

\begin{document} 

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

Frequently, epidemiological studies report estimates of the %Causal inference, in the context of epidemiological studies, is often primarily focused on estimation of the 
average treatment effect (ATE), which is an %statistical 
estimand that summarizes the differences, averaged across a population, in an outcome of interest if all members of a population had been treated (or exposed) compared to if no members of the population had been treated. % the exposure. 
While the ATE can be a useful measure of %in identifying 
whether a treatment %n exposure 
is beneficial or harmful at the population level, it does not provide any information about whether the treatment % an exposure 
is beneficial or harmful for a particular %any given 
individual. Indeed, it is possible that a treatment % exposure 
that is beneficial on average for a population, could benefit some individuals but harm others, i.e., exhibit treatment effect heterogeneity. The field of optimal treatment rules and personalized medicine assumes the existence of treatment effect heterogeneity, and therefore, has as its foundational ideal that % rests on this idea---that 
treatment should not necessarily be a one-sized-fits-all approach; rather, treatments should be given to individuals who would benefit but not to individuals who would not.\cite{} A treatment strategy that uses individual baseline information %persons characteristics 
to tailor treatment to maximize benefit is known as an \textit{optimal individualized treatment rule}.\cite{} %One can learn such an optimal treatment rule by using baseline information to predict which individuals would benefit from a treatment version versus not.\cite{} %In an ideal scenario, public health interventions would only intervene on an individual, using known information about the person, where doing so would be beneficial. 
For example, in a recent comparative effectiveness trial of two common treatments for opioid use disorder (OUD), an optimal treatment rule was learned in which individuals who were homeless were found to have lower risk of relapse if treated with injection naltrexone, whereas individuals with stable housing were found to have lower risk of relapse if treated with the alternative medication, buprenorphine.\cite{rudolph2021optimizing}. 

However, many treatments and exposures are not limited to a single point in time. Instead, treatment can be a long-term process, as is actually the case for medication for OUD in the example above. Consequently, learning an optimal rule for a long-term treatment may involve not just learning the extent to which the comparative treatments' benefits vary across %which treatment works best for a set of 
baseline individual demographic and clinical characteristics, but also learning the extent to which the comparative treatments' benefits vary as (time-varying)  % Just as individualizing treatment assignment (e.g, by applying an optimal treatment rule) may optimize the outcome of interest in the population, treatment the optimal approach to treatment across individuals may not be treat everyone vs. treat  no one, there may not be a one-sized-fits-all approach to whether or not to treat individuals, or whether to treat with one medication over another, there also may not be treatment %the optimal treatment rule can vary 
%across individuals, there may also not be a it may also vary over time within an individual; for example, as a person's 
clinical characteristics or other relevant circumstances evolve. While learning the optimal individualized treatment rule for a fixed-time exposure has been given much attention in the precision medicine literature \citep[e.g.,][]{van2015targeted,MontoyavanderLaanLuedtkeSkeemCoylePetersen2022}, less exists on estimating the time-varying optimal individualized treatment rules, also called \textit{optimal individualized dynamic treatment regimes (ODTR)}. To our knowledge, the much of the work on longitudinal ODTRs has focused %has largely been 
on the theory underlying identification of the causal parameters and estimation strategies \citep{luedtkeSLodtr}. %As is, there are no 
Tutorials or software packages to facilitate implementation of these estimators for %that would make these methods accessible to 
applied researchers are largely absent, which could in part explain why longitudinal ODTR have not been more widely adopted in epidemiology.

We aim to address this gap. In this tutorial-style paper, we describe how to estimate a longitudinal ODTR from observational data. We apply this framework to learn the ODTR for % the buprenorphine (BUP) arms of three harmonized, randomized comparative effectiveness trials to learn the ODTR 
for adapting weekly buprenorphine-naloxone (BUP-NX) dose with respect to minimizing the risk of return to regular opioid use (RROU) over the first 12-weeks of treatment for OUD. This research question is particularly well-suited to being addressed with an ODTR, because currently, addiction medicine clinicians make buprenorphine dosing decisions with little quantitative evidence-based guidance. Under-dosing of medication used in treating OUD, like buprenorphine, is common practice and is considered a contributing factor to poor OUD treatment outcomes \citep{gordon2015patterns,d2019evidence}. Recently, \citet{rudolph2022dose} examined a time-varying but non-individualized dosing strategy where BUP-NX dose was increased whenever a patient indicated opioid use in the prior week and found that this strategy resulted in a 23\% reduced risk of RROU compared to a treatment strategy where BUP-NX dose was held constant. It is of interest to know whether an individualized ODTR learned from the data could reduce risk of RROU even further. After learning the ODTR, we compare the estimated risk of RROU under the ODTR to the estimated risk of RROU using the previously defined, non-individualized strategy of increasing dose in response to opioid use%from the OUD literature 
\citep{rudolph2022dose} and another previously defined treatment rule where dose is held constant after week 3 of treatment. An \texttt{R} package to implement the method we describe is available for download from 
\url{link blinded for review}.
%\href{https://github.com/Rudolph-et-al-MSPH-Epidemiology/odtr/tree/main/pkg}{GitHub}.

%Throughout this tutorial, we are interested in learning an ODTR of when to increase buprenorphine dose over the first 12 weeks of treatment such that RROU is minimized. Briefly, Standard of care treatment for opioid use disorder (OUD) is long-term treatment with one of three medications:  BUP-NX, extended-release injection naltrexone (XR-NTX), or methadone \cite{volkow2019prevention,williams2018developing}. Prior work has shown that BUP-NX and methadone dose is likely key in reducing the risk of RROU. 

\section{Background on optimal individualized dynamic treatment rules}

Individualized dynamic treatment rules are decision making models that assign treatment to observations as a function of the observations' observed history. For example, \citep{} found that individuals diagnosed with OUD and who are housing-unstable have lower risk of RROU when prescribed extended-release injection naltrexone (XR-NTX) versus when prescribed BUP-NX. Using this knowledge, a clinician may choose to prescribe XR-NTX or BUP-NX as a function of their patients housing stability. If this treatment rule minimized the risk of RROU, it would then be considered the \textit{optimal} rule.

Formally, consider a discrete-time process, $t = 1, ..., \tau$, where we observe $n$ i.i.d. copies $O_1, ..., O_n$ of $O = (L_t, A_t, Y) \sim P$. At each time-point $t$, observation $i$ is observed as having covariates $L_t$ that precede a binary treatment indicator $A_t$ and where the outcome variable is $Y$. We use $\overline{X}_t = (X_1, ..., X_t)$ to denote history of a variable $X_t$, and $H_t = (\overline{L}_t, \overline{A}_{t-1})$ to denote the history of all variables up until just before $A_t$. Define $V_t$ as the subset of covariates $H_t$ that will be used in the rule for assigning $A_t$ based on the observed covariate values $v_t$; we call this rule $\d_t(V)$. Symbols with a subscript $n$, (i.e., $Q_n$) represent values estimated from data. Our goal is to learn the treatment rule, among the set of all possible treatment rules ($\mathcal{D}$) that maximizes a beneficial mean outcome (or minimizes a harmful mean outcome) from the observed data, that is: 

$$
\d_{t, \text{opt}}(V) \equiv \argmax _{\d_t(V) \in \mathcal{D}} \E \Big[ Y_{\d_t(V)} \Big]
$$

The target causal parameter under the ODTR is then $\psi := \E[Y_{\d_{t, \text{opt}}(V)}]$, which is the mean outcome under a dynamic treatment rule---the average value of the outcome of interest if, possibly contrary to what was observed, observations had been assigned to treatment according to the rule. Assuming exchangeability, consistency, and positivity are satisfied, $\psi$ is identified and can be estimated using different techniques such as g-computation \citep{}, inverse probability weighting \citep{}, targeted minimum loss-based estimation \citep{tmleLong} or the SDR estimator \cite{luedtke2018sequential}. 

\subsubsection{Approaches to learning the ODTR}

Multiple strategies exist for identifying treatment effect heterogeneity and learning the ODTR; common approaches include outcome weighted learning (OWL) \citep{owl2012}, Q-learning \citep{murphyODTR2003,moodieQlearning2012}, and the ODTR SuperLearner \citep{luedtkeSLodtr,MontoyavanderLaanLuedtkeSkeemCoylePetersen2022}. In what follows, we adopt and describe a "continuous-blip-only" \citep{MontoyavanderLaanLuedtkeSkeemCoylePetersen2022} version of the ODTR SuperLearner. Super learning is an ensemble algorithm that combines predictions from a set of user-defined \textit{learners} (for example, linear regression, decision trees, generalized additive models, etc.) in a way that performs better than any individual learner in the set \citep{breimanStacked,van2007super}. A full explanation of the SuperLearner algorithm is beyond the scope of this paper and we refer the reader to \citet{van2007super} for further background.

\subsubsection{The blip function}

Central to learning the optimal rule with the ODTR SuperLearner is the conditional average treatment effect (CATE), commonly referred to as the blip function. In the case of a fixed-time exposure, the blip function is defined as:

\begin{equation}
  \bar{Q}(V) = \E[Y_1 - Y_0 | V] = \E\Big[Q(L_1, A_1 = 1) - Q(L_1, A_1 = 0) \Big| V\Big]  
\end{equation}

The blip function can be estimated by first estimating $Q(L_1, A_1)$, $Q_n(L_1, A_1)$, using the SuperLearner. We can then obtain estimates of $Q(L_1, A_1 = 1)$ and $Q(L_1, A_1 = 0)$ by predicting from $Q_n(L_1, A_1)$ where $A_1$ is fixed to $1$ and $0$ respectively. The doubly-robust augmented inverse probability weighting (AIPW) transformation of the ATE is then applied and used as an estimate of $Q(L_1, A_1 = 1) - Q(L_1, A_1 = 0) \equiv D_1(Q, g)$, defined as: 

\begin{equation}\label{eif1}
  D_1(Q,g) = \frac{2A_1 - 1}{g_{0, A_1}} \Big( Y - Q(L_1, A_1) \Big) + Q(L_1, 1) - Q(L_1, 0)  
\end{equation}

Our estimate of the blip function is then constructed by regressing, with super learning, $D_1(Q, g)(n)$ on the covariates $V$, $\bar{Q}(V) = \E[D_1(Q, g) | V]$. The optimal treatment for a given observation is then assigned based on the sign of $\bar{Q}_n(V)$. For example, if we wish to maximize $\E [Y_{\d(V)}]$, then we would assign treatment to individuals where $\bar{Q}_n(V)$ is positive and not assign treatment where $\bar{Q}_n(V)$ is negative. 

\subsection{Extension to allow the ODTR to change over time}

We can generalize this procedure to situations where the optimal treatment may change over time by, beginning with the last time and moving backwards, recursively estimating the blip function at each time-point. 

Beginning with time $t = \tau$, we again first estimate $Q(H_t, A_t)$, predict from this model to obtain $Q_n(H_t, A_t = 1)$ and $Q_n(H_t, A_t = 0)$, construct $D_t(Q, g)(n)$ using the AIPW transformation, and regress $D_t(Q, g)(n)$ on $V_t$ to estimate the blip function, $\bar{Q}_{n,t}(V)$. The optimal treatment rule for $A_t$ is then defined as $\d_{n, t, \text{opt}}(V) = I(\bar{Q}_{n,t}(V) > 0)$. This algorithm can then be iterated for times $t = \tau - 1, ..., 1$ by treating $\d_{n, t, \text{opt}}(V)$ as fixed and using $Y_{\d_{A_{t+1}}} \equiv Q_n(H_{t+1}, \d_{n, t+1, \text{opt}}(V))$ as a pseudo-outcome in the model for $Q(H_t, A_t)$ where $Y_{\d_{A_{t+1}}}$ is the estimated counterfactual value $Y$ would have taken if observation were assigned treatment at $t + 1$ according to the optimal rule. We now amend the notation for the result of the AIPW transformation (\ref{eif2}) as $D_t(\d_{A_{t+1}}, Q, g)$ to highlight the dependence on $\d_{n,t+1, \text{opt}}(V)$, the optimal treatment assignment at the next future time-point.

\begin{equation}\label{eif2}
    \begin{split}
    D_t(\d_{A_{t+1}}, Q, g)(0) = &\frac{2A_t - 1}{g_{0, A_t}(0)}\Big(Y - \E_Q[Y_{\d_{A_{t+1}}}|H_t, A_t]\Big) + \\
    &\E_Q[Y_{\d_{A_{t+1}}}|H_t, A_t = 1] - \E_Q[Y_{\d_{A_{t+1}}}|H_t, A_t = 0]
\end{split}
\end{equation}

\section{Application: Learning the ODTR of when to increase buprenorphine dose to minimize RROU}

We now illustrate these methods by applying them to learn a longitudinal ODTR of when to increase BUP-NX dose during the first 12 weeks of treatment to minimize RROU among those randomized to the BUP-NX arms of the three clinical trials. 

\subsection*{Data and measures}
We used data from the BUP-NX arms of three large, harmonized comparative effectiveness trials of medications for the treatment of OUD that were part of the NIDA Clinical Trials Network (CTN): CTN0027, Phase 2 of CTN0030, and CTN0051. CTN0027 was conducted from 2006-2010 and randomized 1,269 participants to either BUP-NX or methadone treatment for 24 weeks \citep{potter2013buprenorphine,saxon2013buprenorphine}. Phase 2 of CTN0030 was conducted from 2006-2009 and randomized 360 participants to BUP-NX and standard medical management vs. BUP-NX and individual drug counseling for 12 weeks \citep{weiss2010multi}. CTN0051 was conducted from 2014-2017 and randomized 570 participants to either extended release naltrexone or BUP-NX treatment for 24 weeks \citep{lee2018comparative}. Using the BUP-NX of all 3 trials resulted in a sample size of N = ? individuals. 

Consistent with both the primary trial papers \citep{} and secondary analyses of these trials \citep{rudolph2022dose}, we used time of return to regular opioid use (RROU) as the outcome of interest, defined as the last day of 7-days of non-study opioid use, or the first-day of the fourth consecutive week of at-least-once-weekly non-study opioid use. Non-study opioid use was determined using: urine drug screens and timeline follow-back interviews. Missed visits and urine screening refusal were considered a positive for opioid use, consistent with the primary trial papers and previous secondary analyses \citep{}, and is considered a reasonable assumption given prior research \citep{}. Our time-varying treatment of interest was an increase in BUP-NX dose, a binary (0/1) variable. We included race/ethnicity, age, biological sex, highest level of past opioid withdrawal discomfort, past-year substance use disorders, history of neurological injury, history of psychiatric disorders, history of IV drug use, and past-30 day drug use as baseline confounders of the time-varying BUP-NX dose increase and time to RROU relationship. We also included most recently prescribed BUP-NX dose and weekly non-study opioid use as time-varying confounders.

\subsection{Statistical analysis}

We first learned an ODTR for when to increase BUP-NX dose that would minimize RROU over the initial 12 weeks of treatment. We did this by xxxxx


Next, we quantified the effect of applying this ODTR versus two non-individualized BUP-NX dosing strategies on RROU by week 12 of treatment. The non-individualized dosing strategies that we used as references were: 1) holding dose constant after week 3 of treatment (what we call the ``constant dosing strategy'') and 2) increasing dose in response to opioid use the previous week (what we call the ``dynamic dosing strategy''). We used a longitudinal sequentially doubly robust (SDR) estimator to estimate the mean counterfactual week-12 relapse under each dosing strategy \citep{luedtke2018sequential}. The SDR estimator incorporated an ensemble of machine learning algorithms \cite{van2007super} to flexibly model relationships (an intercept-only model, a main-effects generalized linear model, multivariate adaptive regression splines [MARS] \cite{friedman1991multivariate}, and extreme gradient boosting \cite{chenXGBoost}). Variances were estimated using the sample variance of the influence curve \cite{luedtke2018sequential}. 

We used \texttt{R} (version 4.2.0) for all analyses \cite{R} with the lmtp \cite{lmtpR, lmtpJASA} and SuperLearner \citep{SuperLearnerPkg} packages. Code to replicate the analyses is available on \href{https://github.com/Rudolph-et-al-MSPH-Epidemiology/odtr}{GitHub}.
%The effect of the constant dosing strategy, $\E[Y^0]$, may be interpreted as the mean counterfactual risk of RROU had all participants had their BUP-NX dose held constant for their duration of treatment. The effect of the dynamic dose increase strategy, $\E[Y_{\d1}]$, may be interpreted as the mean counterfactual risk of RROU if, every time there was previous week opioid use, BUP-NX dose was increased, by any amount, up to the allowable maximum. 

%\subsubsection{Notation}
%Consider a discrete-time process, $t = 1, ..., \tau$, where we observe $n$ i.i.d. copies $O_1, ..., O_n$ of $O = (L_t, A_t, Y) \sim P_0$. At each time-point $t$, observation $i$ is observed as having covariates $L_t$ that precede a binary treatment indicator $A_t$ and where the outcome variable is $Y$. We use $\overline{X}_t = (X_1, ..., X_t)$ to denote history of a variable $X_t$, and $H_t = (\overline{L}_t, \overline{A}_{t-1})$ to denote the history of all variables up until just before $A_t$. Let $g_{0, A_t}(0)$ be the propensity score model representing the probability that an observation will receive treatment at time $t$ and $Q_0(H_t, A_t)$ as the conditional expectation of the outcome $Y$ given the covariate history $H_t$ and treatment $A_t$. 

%\subsubsection{Optimal individualized dynamic treatment rules}


\subsection{Results}
 
We present results for three different statistical parameters of interest, $\psi := \E[Y^0]$, $\E[Y_{\d1}]$, and $\E[Y_{\d_{n, \text{opt}}(V)}]$, corresponding to the risk of returning to regular opioid use by week 12 of treatment following the three dosing strategies: 1) keeping dose constant after week 3 of treatment, 2) raising dose in response to use, and 3) an optimal, though black box rule, based on baseline coviarates and time-varying dose and opioid use measures that minimizes RROU. 

The number of patients who would have BUP-NX dose increased or held constant as well as the mean risk of RROU following the dosing strategies are shown in \ref{tab:t1}. This table is further subdivided by those who were observed as having naturally followed the corresponding treatment strategy. Under strategy of increasing dose in response to use, $\d1$, many individuals would receive dose increases early in treatment, but fewer later in treatment. This is because the likelihood of using opioids decreases in time as BUP-NX treatment continues. In contrast, under the longitudinal ODTR, BUP-NX dose would be increased for the majority of patients in weeks 5, 8, and 11 of treatment; implying a relatively consistent dose increase every three-weeks of treatment. 

We find evidence that the estimated ODTR and the dynamic-use dosing strategy from \citet{rudolph2022dose} would reduce the risk of RROU compared to holding BUP-NX dose constant by 24\% (RR 95\% CI = 0.72, 0.82) and 20\% (RR 95\% CI = 0.68, 0.94) respectively. We find no meaningful difference in the risk of return to week-12 regular use between the ODTR and the dynamic use dosing strategy.

\begin{table}[H]
\caption{Number of patients randomized to receive BUP-NX that were observed as following a given strategy: (Increase) increased dose under the strategy and were observed as increasing dose, or (Constant) had a constant dose under the strategy and were observed as having a constant dose.}
\centering\footnotesize
\begin{tabular}[t]{lrrrrrrrrr|c}
\toprule
 & Wk. 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & $\hat \psi$\\
\midrule
\addlinespace[0.3em]
\multicolumn{11}{l}{Constant dosing strategy}\\
\midrule
\hspace{1em}Constant & 1179 & 1016 & 976 & 948 & 822 & 792 & 761 & 730 & 710 & \multirow{2}{*}{0.49}\\
\hspace{1em}\hspace{1em}$\d_{n, \text{opt}}(V)\,^a$ & 0 & 0 & 933 & 0 & 0 & 756 & 27 & 0 & 642 & \multirow{2}{*}{\includegraphics[width=0.67in, height=0.17in]{figures/pointrange_b9c649cb1cb3.pdf}}\\
\hspace{1em}\hspace{1em}$\d1\,^b$ & 302 & 243 & 222 & 131 & 116 & 120 & 99 & 88 & 91\\
\addlinespace[0.3em]
\midrule
\multicolumn{11}{l}{Learned optimal strategy, $\d_{n, \text{opt}}(V)$}\\
\midrule
\hspace{1em}Increase & 4 & 0 & 55 & 4 & 0 & 25 & 3 & 6 & 12 & \multirow{2}{*}{0.38}\\
\hspace{1em}Constant & 1179 & 1016 & 1 & 948 & 822 & 0 & 734 & 730 & 68 &  \multirow{2}{*}{\includegraphics[width=0.67in, height=0.17in]{figures/pointrange_b9c61b128299.pdf}}\\
\hspace{1em}\emph{Total} & 1183 & 1016 & 56 & 952 & 822 & 25 & 737 & 736 & 80\\
\addlinespace[0.3em]
\midrule
\multicolumn{11}{l}{Increase dose in response to use strategy, $\d1$}\\
\midrule
\hspace{1em}Increase & 76 & 49 & 29 & 19 & 6 & 8 & 6 & 6 & 3 & \multirow{2}{*}{0.39}\\
\hspace{1em}Constant & 716 & 714 & 725 & 704 & 684 & 649 & 644 & 629 & 605 & \multirow{2}{*}{\includegraphics[width=0.67in, height=0.17in]{figures/pointrange_b9c6340d77a8.pdf}}\\
\hspace{1em}\emph{Total} & 792 & 763 & 754 & 723 & 690 & 657 & 650 & 635 & 608\\
\bottomrule \\
\multicolumn{11}{l}{\footnotesize{$^a$ No. of dose increases that would have been indicated applying $\d_0$}}\\
\multicolumn{11}{l}{\footnotesize{$^b$ No. of dose increases that would have been indicated applying $\d1$}}\\
\label{tab:t1}
\end{tabular}
\end{table}

\section{Discussion}

In this paper we learned an optimal, time-varying BUP-NX dosing strategy for minimizing week-12 return to regular opioid-use. Using a doubly-robust estimation procedure, we found evidence that the ODTR would significantly decrease the risk of week-12 return to regular use compared to a strategy where BUP-NX dose is held constant for the duration of treatment. 

The average treatment effect is a limited measure of the causal effect of a public health intervention insofar as its reporting ignores treatment effect heterogeneity as well as realistic and practical constraints for treating different individuals in a population. This is highlighted by our application; clinicians are given little practical guidance on the adjustment of BUP-NX dosing for the long-term treatment of OUD. 

A critique of the ODTR is that it is a black-box model and is likely uninterpretable. However, this does not preclude the use of the ODTR as a useful benchmark for the investigation of simpler and interpretable treatment rules that are guided by constraints expert-knowledge. This was highlighted in our application where an adaptive dosing strategy based on previous week opioid use performed similarly well to the learned ODTR. 

\newpage
\renewcommand{\refname}{References}

\bibliographystyle{unsrt}
\bibliography{lib}

\end{document}
